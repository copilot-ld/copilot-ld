<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Copilot-LD â€“ Architecture</title>
    <link rel="icon" href="favicon.svg" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.min.css"
    />
    <link rel="stylesheet" href="assets/main.css" />
  </head>

  <body>
    <header class="container">
      <hgroup>
        <h1>
          <a href="index.html">ðŸ§¬ <mark>Copilot-LD</mark></a>
        </h1>
        <p>An intelligent agent leveraging GitHub Copilot and Linked Data</p>
      </hgroup>
      <nav>
        <ul>
          <li><a href="concepts.html">Concepts</a></li>
          <li>
            <details class="dropdown">
              <summary>Architecture</summary>
              <ul>
                <li><a href="architecture.html" class="active">Overview</a></li>
                <li><a href="reference.html">Reference</a></li>
              </ul>
            </details>
          </li>
          <li>
            <details class="dropdown">
              <summary>Guides</summary>
              <ul>
                <li><a href="configuration.html">Configuration</a></li>
                <li><a href="processing.html">Processing</a></li>
                <li><a href="deployment.html">Deployment</a></li>
                <li><a href="development.html">Development</a></li>
              </ul>
            </details>
          </li>
        </ul>
      </nav>
    </header>
    <main class="container">
      <h2>Architecture Overview</h2>

      <p>
        Copilot-LD is built as a microservices platform using gRPC for
        inter-service communication, with framework-agnostic business logic
        packages and application-specific extensions. This architecture
        prioritizes modularity, maintainability, and performance.
      </p>

      <aside>
        <nav>
          <h5>Contents</h5>
          <ul>
            <li><a href="#overview">High-Level Overview</a></li>
            <li><a href="#structure">Directory Structure</a></li>
            <li><a href="#relationships">Component Relationships</a></li>
            <li><a href="#online">Online Request Flow</a></li>
            <li><a href="#offline">Offline Processing Flow</a></li>
            <li><a href="#codegen">Code Generation Workflow</a></li>
            <li><a href="#deployment">Deployment Architecture</a></li>
            <li><a href="#security">Security Architecture</a></li>
            <li><a href="#next">Next Steps</a></li>
          </ul>
        </nav>
        <hr />
      </aside>

      <h3 id="overview">High-Level Overview</h3>

      <p>
        The system is organized into three primary layers, each with distinct
        responsibilities:
      </p>

      <ul>
        <li>
          <strong>Extensions</strong>: Application adapters that expose the
          platform through different interfaces (web UI, Teams bot, REST API)
        </li>
        <li>
          <strong>Services</strong>: Single-responsibility microservices
          communicating via gRPC with Protocol Buffers
        </li>
        <li>
          <strong>Packages</strong>: Reusable business logic libraries that
          services and extensions import
        </li>
      </ul>

      <h3 id="structure">Directory Structure</h3>

      <pre>
copilot-ld/
â”œâ”€â”€ services/              # gRPC microservices
â”‚   â”œâ”€â”€ agent/            # Request orchestration
â”‚   â”œâ”€â”€ memory/           # Conversation storage
â”‚   â”œâ”€â”€ llm/              # Language model interface
â”‚   â”œâ”€â”€ vector/           # Similarity search
â”‚   â”œâ”€â”€ graph/            # Graph queries
â”‚   â””â”€â”€ tool/             # Tool execution proxy
â”œâ”€â”€ extensions/           # Application adapters
â”‚   â”œâ”€â”€ web/             # Web interface
â”‚   â””â”€â”€ teams/           # Teams bot (example)
â”œâ”€â”€ packages/            # Business logic libraries
â”‚   â”œâ”€â”€ libagent/        # Agent orchestration
â”‚   â”œâ”€â”€ libmemory/       # Memory management
â”‚   â”œâ”€â”€ libvector/       # Vector operations
â”‚   â”œâ”€â”€ libgraph/        # Graph operations
â”‚   â”œâ”€â”€ libresource/     # Resource management
â”‚   â”œâ”€â”€ librpc/          # gRPC infrastructure
â”‚   â”œâ”€â”€ libtype/         # Generated types
â”‚   â””â”€â”€ lib.../          # Additional utilities
â”œâ”€â”€ proto/               # Protocol Buffer schemas
â”œâ”€â”€ tools/               # Optional tool extensions
â”œâ”€â”€ generated/           # Generated code artifacts
â”œâ”€â”€ data/                # Runtime and processed data
â””â”€â”€ scripts/             # Development utilities
      </pre>

      <h3 id="relationships">Component Relationships</h3>

      <h4>Communication Patterns</h4>

      <ul>
        <li>
          <strong>Client â†’ Extension</strong>: HTTP/HTTPS (REST endpoints)
        </li>
        <li>
          <strong>Extension â†’ Services</strong>: gRPC with HMAC authentication
        </li>
        <li>
          <strong>Service â†’ Service</strong>: gRPC with HMAC authentication
        </li>
        <li>
          <strong>All Layers â†’ Packages</strong>: Direct imports (ES modules)
        </li>
      </ul>

      <h4>Service Layer</h4>

      <p>
        Each service is a thin gRPC adapter around business logic packages. The
        Agent service orchestrates requests by calling other services as needed:
      </p>

      <ul>
        <li>
          <strong>Agent</strong>: Orchestrates request processing and tool
          calling loops
        </li>
        <li>
          <strong>Memory</strong>: Manages conversation history with budget
          allocation
        </li>
        <li>
          <strong>LLM</strong>: Interfaces with language models for embeddings
          and completions
        </li>
        <li>
          <strong>Vector</strong>: Performs similarity search across dual
          indexes
        </li>
        <li>
          <strong>Graph</strong>: Executes pattern-based queries on RDF graphs
        </li>
        <li>
          <strong>Tool</strong>: Proxies tool calls from agent to
          implementations
        </li>
      </ul>

      <p>
        For detailed service implementations, see the
        <a href="reference.html">Reference Guide</a>.
      </p>

      <h4>Package Layer</h4>

      <p>
        Business logic packages (<code>@copilot-ld/lib*</code>) contain
        framework-agnostic code that services import. This separation enables:
      </p>

      <ul>
        <li>
          <strong>Testability</strong>: Unit test logic without service
          infrastructure
        </li>
        <li>
          <strong>Reusability</strong>: Same code powers services and CLI tools
        </li>
        <li>
          <strong>Maintainability</strong>: Clear separation between
          communication and computation
        </li>
      </ul>

      <p>
        For complete package catalog, see the
        <a href="reference.html#package-catalog">Reference Guide</a>.
      </p>

      <h4>Extension Layer</h4>

      <p>
        Extensions are application-specific adapters that call the Agent service
        via gRPC. They handle:
      </p>

      <ul>
        <li>
          <strong>Protocol Translation</strong>: Convert HTTP/WebSocket/Bot
          protocols to gRPC
        </li>
        <li>
          <strong>Authentication</strong>: Validate user credentials and manage
          sessions
        </li>
        <li>
          <strong>Input Validation</strong>: Sanitize and validate user input
        </li>
        <li><strong>Rate Limiting</strong>: Protect backend from abuse</li>
      </ul>

      <h3 id="online">Online Request Flow</h3>

      <p>
        The following sequence diagram shows how a user request flows through
        the system at runtime. The Agent makes autonomous decisions about which
        services to call and when:
      </p>

      <pre class="mermaid">
sequenceDiagram
    participant Client
    participant Extension as Extensions
    participant Agent as Agent service
    participant Memory as Memory service
    participant LLM as LLM service
    participant Tool as Tool service
    participant Vector as Vector service
    participant ContentIndex as Content Vector Index
    participant ResourceIndex as Resource Index
    participant GitHub as GitHub API

    Client->>Extension: REST request
    Extension->>Agent: RPC request (ProcessRequest)

    Note right of Agent: GitHub validation
    Agent->>GitHub: GET /user (validate token)
    GitHub-->>Agent: 200 OK (user)

    Agent->>ResourceIndex: Get/Create conversation
    Agent->>ResourceIndex: Put user message (scoped to conversation)
    Agent->>ResourceIndex: Get assistant by id (from config)
    Note right of Agent: Compute token budget (budget = config.budget.tokens - assistant.content.tokens) and derive allocation

    Agent->>Memory: Get (for conversation, with budget/allocation)
    Memory-->>Agent: Window (tools, history)

    Agent->>ResourceIndex: Resolve window identifiers (tools/history)
    ResourceIndex-->>Agent: Resources (policy-filtered)

    Note over Agent: Autonomous Tool Calling Loop (max 10 iterations)
    loop Until no tool calls or max iterations
        Agent->>LLM: CreateCompletions (assistant + tasks + tools + history)
        LLM-->>Agent: Completion with autonomous tool call decisions
        
        alt Tool calls present
            loop For each autonomous tool call
                Agent->>Tool: Call (tool call + github_token)
                Tool-->>Agent: Tool result message
                Note right of Agent: Add tool result to messages
            end
            Note right of Agent: Continue loop with updated messages
        else No tool calls
            Note right of Agent: Exit loop - completion ready
        end
    end

    Agent->>ResourceIndex: Put final completion message (scoped to conversation)

    Agent-->>Extension: RPC response (with conversation_id)
    Extension-->>Client: REST response
      </pre>

      <h4>Key Characteristics</h4>

      <ul>
        <li>
          <strong>Sequential per request</strong>: Each request is processed
          step-by-step
        </li>
        <li>
          <strong>Concurrent requests</strong>: Multiple requests can be handled
          in parallel
        </li>
        <li>
          <strong>Autonomous decisions</strong>: Agent decides which tools to
          call dynamically
        </li>
        <li>
          <strong>Policy filtering</strong>: All resource access respects access
          policies
        </li>
        <li>
          <strong>Budget management</strong>: Token budgets allocated across
          context components
        </li>
      </ul>

      <h3 id="offline">Offline Processing Flow</h3>

      <p>
        Before the system can answer questions, knowledge must be processed into
        searchable formats. This happens offline during the build process:
      </p>

      <pre class="mermaid">
sequenceDiagram
    participant Dev as Developer
    participant Scripts as Processing Scripts
    participant HTML as HTML Files
    participant ResourceProc as Resource Processor
    participant ResourceIndex as Resource Index
    participant LLM as LLM API
    participant VectorProc as Vector Processor
    participant VectorIndex as Vector Indexes

    Note over Dev,VectorIndex: Offline Processing Pipeline

    Dev->>Scripts: npm run process

    Note over Scripts: 1. Assistant Processing
    Scripts->>ResourceIndex: Load assistants from config/assistants.yml
    ResourceIndex-->>Scripts: Assistants stored

    Note over Scripts: 2. Resource Processing
    Scripts->>HTML: Read knowledge files
    HTML-->>ResourceProc: HTML with microdata

    loop For each microdata item
        ResourceProc->>ResourceProc: Extract content & metadata
        ResourceProc->>ResourceIndex: Store resource with URI identifier
    end

    Note over Scripts: 3. Descriptor Generation
    loop For each resource
        Scripts->>LLM: Generate descriptor (batched)
        LLM-->>Scripts: Descriptor text
        Scripts->>ResourceIndex: Update resource with descriptor
    end

    Note over Scripts: 4. Vector Processing
    Scripts->>ResourceIndex: Load all resources

    loop Batch processing
        ResourceProc->>LLM: Create embeddings (content + descriptors, batched)
        LLM-->>VectorProc: Vector embeddings
        VectorProc->>VectorIndex: Add to content index
        VectorProc->>VectorIndex: Add to descriptor index
    end

    VectorIndex-->>Scripts: Indexes persisted to disk
    Scripts-->>Dev: Processing complete
      </pre>

      <h4>Processing Stages</h4>

      <ol>
        <li>
          <strong>Assistant Configuration</strong>: Load assistant definitions
          from YAML
        </li>
        <li>
          <strong>Resource Extraction</strong>: Parse HTML microdata into
          individual resources
        </li>
        <li>
          <strong>Descriptor Generation</strong>: Generate AI descriptions of
          resource purpose
        </li>
        <li>
          <strong>Embedding Creation</strong>: Convert content and descriptors
          to vectors
        </li>
        <li>
          <strong>Index Building</strong>: Create dual indexes for similarity
          search
        </li>
      </ol>

      <p>
        For detailed processing workflows, see the
        <a href="processing.html">Processing Guide</a>.
      </p>

      <h3 id="codegen">Code Generation Workflow</h3>

      <p>
        Protocol Buffer schemas in <code>proto/</code> and <code>tools/</code>
        are compiled into JavaScript types and service infrastructure:
      </p>

      <pre>
Developer defines schema â†’ npm run codegen â†’ Generated artifacts
                                              â†“
proto/agent.proto â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ generated/types/types.js
proto/memory.proto                     generated/services/agent/service.js
tools/hash.proto                       generated/services/agent/client.js
                                       generated/proto/ (copied schemas)
      </pre>

      <p>
        Services automatically create symlinks at startup so packages can access
        generated code via <code>@copilot-ld/libtype</code> and
        <code>@copilot-ld/librpc</code>.
      </p>

      <p>
        For code generation details, see the
        <a href="reference.html#code-generation">Reference Guide</a>.
      </p>

      <h3 id="deployment">Deployment Architecture</h3>

      <p>
        The system can be deployed in multiple configurations depending on your
        needs:
      </p>

      <h4>Local Development</h4>

      <pre><code># All services run on localhost with individual ports
npm run dev

# Services available at:
# - Web Extension: http://localhost:3000/web
# - Agent: localhost:3002 (gRPC, internal)
# - Memory: localhost:3003 (gRPC, internal)
# - etc.</code></pre>

      <h4>Docker Compose</h4>

      <pre><code># Services run in Docker network with internal communication
docker-compose up

# Only web extension exposed externally
# Backend services isolated in Docker network</code></pre>

      <h4>Production (AWS/Cloud)</h4>

      <ul>
        <li>
          <strong>Load Balancer</strong>: Application Load Balancer routes to
          extensions
        </li>
        <li>
          <strong>Container Orchestration</strong>: ECS/Kubernetes manages
          services
        </li>
        <li>
          <strong>Network Isolation</strong>: Backend services in private VPC
        </li>
        <li>
          <strong>Service Discovery</strong>: DNS-based service resolution
        </li>
      </ul>

      <p>
        For deployment instructions, see the
        <a href="deployment.html">Deployment Guide</a>.
      </p>

      <h3 id="security">Security Architecture</h3>

      <p>Security is built into every layer of the architecture:</p>

      <h4>Network Isolation</h4>

      <ul>
        <li>
          <strong>External Access</strong>: Only extensions exposed via load
          balancer
        </li>
        <li>
          <strong>Internal Services</strong>: Backend services not accessible
          from outside
        </li>
        <li>
          <strong>gRPC Communication</strong>: All inter-service calls require
          HMAC authentication
        </li>
      </ul>

      <h4>Authentication</h4>

      <ul>
        <li>
          <strong>Service-to-Service</strong>: HMAC signatures with time-limited
          tokens
        </li>
        <li>
          <strong>GitHub Integration</strong>: OAuth device flow for user
          authentication
        </li>
        <li>
          <strong>API Keys</strong>: LLM service uses API keys for external
          calls
        </li>
      </ul>

      <h4>Access Control</h4>

      <ul>
        <li>
          <strong>Policy-Based</strong>: All resource access filtered by
          policies
        </li>
        <li>
          <strong>Conversation Scoping</strong>: Users only access their own
          conversations
        </li>
        <li>
          <strong>Tool Restrictions</strong>: Tools can be restricted by
          configuration
        </li>
      </ul>

      <p>
        For security implementation details, see the
        <a href="reference.html#security-implementation">Reference Guide</a>.
      </p>

      <h3 id="next">Next Steps</h3>

      <p>Now that you understand the architecture, explore:</p>

      <ul>
        <li>
          <strong><a href="reference.html">Reference</a></strong
          >: Detailed implementation information
        </li>
        <li>
          <strong><a href="configuration.html">Configuration</a></strong
          >: Set up your environment
        </li>
        <li>
          <strong><a href="processing.html">Processing</a></strong
          >: Prepare your knowledge base
        </li>
        <li>
          <strong><a href="development.html">Development</a></strong
          >: Local development workflow
        </li>
        <li>
          <strong><a href="deployment.html">Deployment</a></strong
          >: Deploy to production
        </li>
      </ul>
    </main>
    <footer class="container">
      <p>Â© D. Olsson</p>
    </footer>

    <script type="module">
      import mermaid from "https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs";
    </script>
  </body>
</html>
