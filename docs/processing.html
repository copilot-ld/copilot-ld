<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Copilot-LD â€“ Processing Guide</title>
    <link rel="icon" href="favicon.svg" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.min.css"
    />
    <link rel="stylesheet" href="assets/main.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css"
    />
  </head>
  <body>
    <header class="container">
      <hgroup>
        <h1>
          <a href="index.html">ðŸ§¬ <mark>Copilot-LD</mark></a>
        </h1>
        <p>An intelligent agent leveraging GitHub Copilot and Linked Data</p>
      </hgroup>
      <nav>
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="concepts.html">Concepts</a></li>
          <li>
            <details class="dropdown">
              <summary>Docs</summary>
              <ul>
                <li><a href="architecture.html">Architecture</a></li>
                <li><a href="reference.html">Reference</a></li>
              </ul>
            </details>
          </li>
          <li>
            <details class="dropdown">
              <summary>Guides</summary>
              <ul>
                <li><a href="configuration.html">Configuration</a></li>
                <li><a href="processing.html" class="active">Processing</a></li>
                <li><a href="deployment.html">Deployment</a></li>
                <li><a href="development.html">Development</a></li>
              </ul>
            </details>
          </li>
        </ul>
      </nav>
    </header>
    <main class="container">
      <h2>Processing Guide</h2>

      <p>
        Complete guide to processing knowledge bases, resources, tools, and
        vectors in Copilot-LD. This covers the offline pipeline that transforms
        raw knowledge into searchable, embedded content.
      </p>

      <aside>
        <nav>
          <h5>Contents</h5>
          <ul>
            <li><a href="#prerequisites">Prerequisites</a></li>
            <li><a href="#overview">Overview</a></li>
            <li><a href="#process">1. Processing All Data</a></li>
            <li><a href="#structure">2. Knowledge Base Structure</a></li>
            <li><a href="#resources">3. Resource Processing</a></li>
            <li><a href="#tools">4. Tool Processing</a></li>
            <li><a href="#vectors">5. Vector Processing</a></li>
            <li><a href="#management">6. Data Management Utilities</a></li>
            <li><a href="#querying">7. Querying Processed Data</a></li>
            <li><a href="#next">Next Steps</a></li>
          </ul>
        </nav>
        <hr />
      </aside>

      <h3 id="prerequisites">Prerequisites</h3>
      <ul>
        <li><a href="configuration.html">Configuration Guide</a> completed</li>
        <li>
          Basic understanding of HTML microdata. See
          <a
            href="https://developer.mozilla.org/en-US/docs/Web/HTML/Guides/Microdata"
            target="_blank"
            >Using microdata in HTML</a
          >
          on MDN Web Docs.
        </li>
      </ul>

      <h3 id="overview">Overview</h3>
      <p>
        The Copilot-LD processing pipeline transforms your knowledge base into
        searchable resources, tool definitions, and vector embeddings. The
        system processes assistants, HTML content, tools, and vectors
        automatically in the correct sequence.
      </p>

      <h3 id="process">1. Processing All Data</h3>
      <p>
        Process assistants, knowledge base content, tools, and vectors with a
        single command. The system handles all stages automatically:
      </p>

      <pre><code class="language-bash">npm run process</code></pre>

      <h3 id="structure">2. Knowledge Base Structure</h3>
      <p>
        Copilot-LD uses HTML files with structured microdata to organize
        knowledge. This approach provides semantic context and enables accurate
        content extraction.
      </p>

      <h4>HTML with Microdata</h4>
      <p>
        Knowledge files should use HTML5 microdata with Schema.org vocabularies
        to structure content:
      </p>

      <pre><code class="language-markup">&lt;!-- Example: data/knowledge/security-practices.html --&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Security Best Practices&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;article itemscope itemtype="http://schema.org/Article"&gt;
        &lt;h1 itemprop="headline"&gt;Docker Security Best Practices&lt;/h1&gt;
        &lt;div itemprop="articleBody"&gt;
            &lt;p&gt;Always use specific image tags instead of 'latest' to ensure reproducible builds.&lt;/p&gt;
            &lt;p&gt;Implement multi-stage builds to reduce attack surface and image size.&lt;/p&gt;
            &lt;p&gt;Run containers as non-root users whenever possible.&lt;/p&gt;
        &lt;/div&gt;
    &lt;/article&gt;
    
    &lt;article itemscope itemtype="http://schema.org/Article"&gt;
        &lt;h1 itemprop="headline"&gt;Container Registry Security&lt;/h1&gt;
        &lt;div itemprop="articleBody"&gt;
            &lt;p&gt;Scan container images for vulnerabilities before deployment.&lt;/p&gt;
            &lt;p&gt;Use private registries for proprietary or sensitive applications.&lt;/p&gt;
        &lt;/div&gt;
    &lt;/article&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre>

      <h4>Schema.org Types</h4>
      <p>
        The processing pipeline works with any Schema.org types. Common examples
        include:
      </p>
      <ul>
        <li>
          <a href="https://schema.org/Article" target="_blank"
            ><code>Article</code></a
          >: Technical articles, best practices, guides
        </li>
        <li>
          <a href="https://schema.org/HowTo" target="_blank"
            ><code>HowTo</code></a
          >: Step-by-step procedures and tutorials
        </li>
        <li>
          <a href="https://schema.org/FAQPage" target="_blank"
            ><code>FAQPage</code></a
          >: Frequently asked questions
        </li>
        <li>
          <a href="https://schema.org/TechArticle" target="_blank"
            ><code>TechArticle</code></a
          >: Technical documentation
        </li>
      </ul>
      <p>
        You can use any Schema.org type that fits your content structure and
        semantic needs.
      </p>

      <h4>Example Knowledge Base</h4>
      <p>
        Copilot-LD includes example knowledge files to demonstrate the HTML
        microdata structure:
      </p>

      <pre><code class="language-bash"># Copy example knowledge base to your data directory
cp -r examples/knowledge data/</code></pre>

      <h3 id="resources">3. Resource Processing</h3>
      <p>
        The resource processor extracts structured content from HTML files and
        creates searchable resources stored in the
        <code>data/resources/</code> directory. This happens automatically when
        you run <code>npm run process</code>.
      </p>

      <h4>Custom CSS Selectors</h4>
      <p>
        By default, the processor looks for <code>[itemscope]</code> elements.
        For advanced usage, you can run the underlying script directly with
        custom selectors:
      </p>

      <pre><code class="language-bash"># Process only article elements
node scripts/resources.js --selector "article[itemscope]"

# Process multiple content types
node scripts/resources.js --selector "[itemtype*='Article'], [itemtype*='HowTo']"</code></pre>

      <h4>Output Structure</h4>
      <p>
        Resource processing creates individual JSON files in
        <code>data/resources/</code> with Copilot-LD (CLD) identifiers:
      </p>

      <pre><code class="language-bash">data/resources/
â”œâ”€â”€ common.Message.{hash}.json          # Individual message resources
â”œâ”€â”€ common.Assistant.{name}.json        # Assistant configurations
â””â”€â”€ common.Conversation.{uuid}.json     # Conversation metadata
â”œâ”€â”€ tool.ToolFunction.{name}.json       # Tool definitions</code></pre>

      <h5>Resource Format</h5>
      <p>Each extracted resource contains:</p>
      <ul>
        <li>
          <strong>Identifier</strong>: Unique resource ID based on content hash
        </li>
        <li>
          <strong>Content</strong>: Extracted text content from the HTML element
        </li>
        <li>
          <strong>Metadata</strong>: Schema.org type, source file, extraction
          timestamp
        </li>
        <li>
          <strong>Descriptor</strong>: AI-generated description of the content's
          purpose and applicability
        </li>
      </ul>

      <h4>Assistant Processing</h4>
      <p>
        The resource processor also processes assistant configurations, creating
        resources for each defined assistant persona. This enables the system to
        search and select appropriate assistants based on context.
      </p>

      <h3 id="tools">4. Tool Processing</h3>
      <p>
        Tool processing generates OpenAI-compatible JSON schemas from Protocol
        Buffer definitions, enabling dynamic tool registration and validation.
        This happens automatically when you run <code>npm run process</code>.
      </p>

      <h4>Protocol Buffer Tool Definitions</h4>
      <p>
        Tools are defined using Protocol Buffer messages that describe their
        parameters and functionality. The tool processor scans
        <code>tools/</code> directory for <code>*.proto</code> files:
      </p>

      <pre><code class="language-javascript">// examples/tools/hash.proto
syntax = "proto3";

package hash;

service Hash {
  rpc Sha256(HashRequest) returns (HashResponse);
  rpc Md5(HashRequest) returns (HashResponse);
}

message HashRequest {
  string input = 1;
}

message HashResponse {
  string hash = 1;
  string algorithm = 2;
}</code></pre>

      <h4>JSON Schema Generation</h4>
      <p>
        The tool processor converts Protocol Buffer definitions into
        OpenAI-compatible JSON schemas that can be used for LLM tool calling.
        Each RPC method in the service definition becomes a separate tool
        function:
      </p>

      <pre><code class="language-javascript">// Generated schema for sha256_hash tool
{
  "type": "object",
  "properties": {
    "input": {
      "type": "string",
      "description": "input field"
    }
  },
  "required": ["input"]
}</code></pre>

      <h4>Tool Configuration</h4>
      <p>
        Generated tool schemas are stored as individual JSON files in
        <code>data/resources/</code> with the pattern
        <code>tool.ToolFunction.{name}.json</code> and automatically registered
        with the Tool service during startup. Each tool entry includes:
      </p>
      <ul>
        <li>
          <strong>Tool Name</strong>: Method name from the Protocol Buffer
          service (e.g., <code>sha256_hash</code>, <code>md5_hash</code>)
        </li>
        <li>
          <strong>Parameters Schema</strong>: JSON schema for validating tool
          parameters
        </li>
        <li>
          <strong>Purpose Description</strong>: AI-generated description of tool
          functionality
        </li>
        <li>
          <strong>Usage Instructions</strong>: Detailed instructions for proper
          tool usage
        </li>
        <li>
          <strong>Applicability Guidelines</strong>: When and when not to use
          the tool
        </li>
      </ul>

      <h5>Example Tool Resource</h5>
      <p>
        The hash tool generates separate resources for each RPC method. Here's
        the generated
        <code>sha256_hash</code> tool resource:
      </p>

      <pre><code class="language-json">{
  "id": {
    "type": "tool.ToolFunction",
    "name": "sha256_hash"
  },
  "descriptor": {
    "tokens": 89,
    "purpose": "Create deterministic SHA-256 hash of input text.",
    "instructions": "Input: Text string in 'input' field. Output: 64-character hexadecimal SHA-256 hash.",
    "applicability": "Use ONLY when user explicitly requests SHA-256 hashing. DO NOT use for search or content analysis.",
    "evaluation": "Returns exactly 64-character hexadecimal string."
  },
  "name": "sha256_hash",
  "parameters": {
    "type": "object",
    "properties": {
      "input": {
        "type": "string",
        "description": "input field"
      }
    },
    "required": ["input"]
  }
}</code></pre>

      <h3 id="vectors">5. Vector Processing</h3>
      <p>
        Vector processing creates embeddings of resource content and descriptors
        for efficient similarity search and retrieval-augmented generation. This
        happens automatically when you run <code>npm run process</code>.
      </p>

      <h4>Embedding Strategy</h4>
      <p>The vector processor creates two types of embeddings:</p>

      <h5>Content Embeddings</h5>
      <ul>
        <li>
          <strong>Purpose</strong>: Direct semantic search of actual content
        </li>
        <li>
          <strong>Source</strong>: Full text content extracted from HTML
          elements
        </li>
        <li>
          <strong>Use Case</strong>: Finding specific information, facts, and
          detailed explanations
        </li>
      </ul>

      <h5>Descriptor Embeddings</h5>
      <ul>
        <li><strong>Purpose</strong>: Conceptual and categorical search</li>
        <li>
          <strong>Source</strong>: AI-generated descriptions of content purpose
          and applicability
        </li>
        <li>
          <strong>Use Case</strong>: Finding relevant content types,
          methodologies, and approaches
        </li>
      </ul>

      <h4>Vector Storage</h4>
      <p>Embeddings are stored in <code>data/vectors/</code> as JSONL files:</p>

      <pre><code class="language-bash">data/vectors/
â”œâ”€â”€ content.jsonl         # Content-based embeddings  
â””â”€â”€ descriptors.jsonl     # Descriptor-based embeddings</code></pre>

      <p>Each vector entry contains:</p>
      <ul>
        <li>
          <strong>Identifier</strong>: Links back to the original resource
        </li>
        <li>
          <strong>Embedding</strong>: 1536-dimensional vector from OpenAI
          text-embedding-3-small
        </li>
      </ul>

      <h3 id="management">6. Data Management Utilities</h3>
      <p>
        Copilot-LD includes utilities for managing processed data across
        development and deployment environments. These commands require that the
        <a href="deployment.html">Deployment Guide</a> be completed first for
        proper S3 configuration.
      </p>

      <h4>Upload Processed Data</h4>
      <p>
        Upload all processed data from local storage to S3-compatible remote
        storage:
      </p>

      <pre><code class="language-bash">npm run upload</code></pre>

      <h5>Upload Process</h5>
      <p>The upload utility synchronizes these storage areas:</p>
      <ul>
        <li><strong>config/</strong>: Configuration files and secrets</li>
        <li>
          <strong>generated/</strong>: Generated code and Protocol Buffer
          artifacts
        </li>
        <li>
          <strong>memories/</strong>: Conversation history and chat memories
        </li>
        <li><strong>resources/</strong>: Processed knowledge base resources</li>
        <li>
          <strong>vectors/</strong>: Embedding indices for semantic search
        </li>
      </ul>

      <h5>S3 Configuration Requirements</h5>
      <p>
        Upload requires S3-compatible storage configuration. See the
        <a href="configuration.html#storage-configuration"
          >Storage Configuration</a
        >
        section in the Configuration Guide for complete setup details including
        environment variables and MinIO options.
      </p>

      <h4>Download Processed Data</h4>
      <p>Download pre-processed data bundle from remote storage:</p>

      <pre><code class="language-bash">npm run download</code></pre>

      <h5>Download Process</h5>
      <p>
        The download utility retrieves and extracts a
        <code>bundle.tar.gz</code> archive containing generated code and
        processed data. This is useful for:
      </p>
      <ul>
        <li>
          <strong>Quick Setup</strong>: Skip processing steps with pre-processed
          data
        </li>
        <li>
          <strong>CI/CD Pipelines</strong>: Download consistent data sets for
          automated deployments
        </li>
        <li>
          <strong>Team Synchronization</strong>: Share processed knowledge base
          across team members
        </li>
      </ul>

      <h5>Bundle Configuration</h5>
      <p>Configure the download source in <code>config/config.json</code>:</p>
      <pre><code class="language-yaml">tool:
  download:
    owner: "your-organization"
    repo: "your-knowledge-repository"</code></pre>

      <h4>Data Management Workflow</h4>
      <p>Typical workflow for managing processed data across environments:</p>

      <h5>Development Environment</h5>
      <pre><code class="language-bash"># Process knowledge base locally
npm run process

# Upload processed data to S3
npm run upload</code></pre>

      <h5>Production Environment</h5>
      <pre><code class="language-bash"># Download pre-processed data bundle
npm run download

# Or synchronize from S3 if using upload/download pattern
# Deploy with processed data available</code></pre>

      <h4>Storage Monitoring</h4>
      <p>Monitor data storage usage and processing status:</p>

      <pre><code class="language-bash"># Check local storage sizes
du -sh data/*/

# Monitor S3 bucket usage (if using AWS)
aws s3 ls s3://your-copilot-ld-bucket --recursive --human-readable --summarize

# Check resource count by type
ls data/resources/ | grep "Message" | wc -l
ls data/resources/ | grep "ToolFunction" | wc -l
ls data/resources/ | grep "Assistant" | wc -l</code></pre>

      <h3 id="querying">7. Querying Processed Data</h3>
      <p>
        Query the extracted graph data using the query script. Queries use the
        format
        <code>&lt;subject&gt; &lt;predicate&gt; &lt;object&gt;</code> where any
        field can be replaced with <code>?</code> as a wildcard:
      </p>

      <pre><code class="language-bash"># Interactive mode
npm run query

# Pipe queries
echo "? headline ?" | npm run query
echo '? name "Agile Values"' | npm run query
echo "#agile-manifesto ? ?" | npm run query</code></pre>

      <h4>Common Query Patterns</h4>
      <p>Find resources of a certain type:</p>
      <pre><code class="language-bash">echo "? http://www.w3.org/1999/02/22-rdf-syntax-ns#type TechArticle" | npm run query</code></pre>

      <p>Find resources using the type shorthand:</p>
      <pre><code class="language-bash">echo "? type DefinedTerm" | npm run query</code></pre>

      <p>Find all resources with any title:</p>
      <pre><code class="language-bash">echo "? http://purl.org/dc/terms/title ?" | npm run query</code></pre>

      <h4>Query Tips</h4>
      <ul>
        <li>
          Use quotes for multi-word strings: <code>"Working software"</code>
        </li>
        <li>Use <code>/limit 10</code> to control result count</li>
        <li>
          Reference HTML element IDs directly: <code>#agile-manifesto</code>
        </li>
      </ul>

      <h3 id="next">Next Steps</h3>
      <p>Once processing is complete, proceed to:</p>
      <ul>
        <li>
          <a href="deployment.html">Deployment Guide</a> - Deploy the system
          with your processed knowledge base
        </li>
        <li>
          <a href="development.html">Development Guide</a> - Set up local
          development environment for further customization
        </li>
        <li>
          <a href="architecture.html">Architecture Overview</a> - Understand how
          processing fits into the overall system
        </li>
      </ul>
    </main>
    <footer class="container">
      <p>Â© D. Olsson</p>
    </footer>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-markup.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-javascript.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-json.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-yaml.min.js"></script>
  </body>
</html>
